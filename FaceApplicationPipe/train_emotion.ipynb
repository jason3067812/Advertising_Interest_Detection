{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "colab": {},
    "colab_type": "code",
    "id": "91Ri7fCmTMAA"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import zipfile\n",
    "import os\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot\n",
    "from math import sqrt \n",
    "import numpy as np \n",
    "import scipy.misc \n",
    "from IPython.display import display \n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator \n",
    "from keras.utils import plot_model\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.regularizers import l1, l2\n",
    "from keras.utils import plot_model\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "from pylab import rcParams\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "wuQVMViCCM0E",
    "outputId": "779585d7-ad43-4a7b-e26f-b34327169783"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>pixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>231 212 156 164 174 138 161 173 182 200 106 38...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   emotion                                             pixels\n",
       "0        0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...\n",
       "1        0  151 150 147 155 148 133 111 140 170 174 182 15...\n",
       "2        2  231 212 156 164 174 138 161 173 182 200 106 38...\n",
       "3        4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...\n",
       "4        6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data= pd.read_csv(r\"C:\\Users\\ee527\\Desktop\\train.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "9747ec111b84d59523991febdf88f94bfb9876cd",
    "colab": {},
    "colab_type": "code",
    "id": "G_J2TpOATMAF"
   },
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = 15, 10"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FYV6Xxa3Pu4G"
   },
   "source": [
    "checking the number of each class in our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "73867bf44a012e4c966616fc7cbfc2cb2eff9fe8",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "AiOfpHMmTMAI",
    "outputId": "42fe4b90-cfde-4489-cdff-1decc1de8e46"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    7215\n",
       "6    4965\n",
       "4    4830\n",
       "2    4097\n",
       "0    3995\n",
       "5    3171\n",
       "1     436\n",
       "Name: emotion, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.emotion.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "29ef4814d4323333088baae02d1a96f83db1c3f4",
    "colab": {},
    "colab_type": "code",
    "id": "YQ_cUIEITMAL"
   },
   "outputs": [],
   "source": [
    "num_classes = 7\n",
    "width = 48\n",
    "height = 48\n",
    "emotion_labels = [\"Angry\", \"Disgust\", \"Fear\", \"Happy\", \"Sad\", \"Surprise\", \"Neutral\"]\n",
    "classes=np.array(emotion_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "15d98d711962aeab1d12478d9b3a9b8419cc49c5",
    "colab": {},
    "colab_type": "code",
    "id": "0SyYlQEMTMAR"
   },
   "outputs": [],
   "source": [
    "depth = 1\n",
    "height = int(sqrt(len(data.pixels[0].split()))) \n",
    "width = int(height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "2a7111d3045580ae1ff21b7ae770c4be7abeebbe",
    "colab": {},
    "colab_type": "code",
    "id": "VlJV9uAqTMAX"
   },
   "outputs": [],
   "source": [
    "\n",
    "def gray_to_rgb(im):\n",
    "  '''\n",
    "  converts images from single channel images to 3 channels\n",
    "  '''\n",
    "\n",
    "  w, h = im.shape\n",
    "  ret = np.empty((w, h, 3), dtype=np.uint8)\n",
    "  ret[:, :, 2] =  ret[:, :, 1] =  ret[:, :, 0] =  im\n",
    "  return ret\n",
    "\n",
    "def convert_to_image(pixels, mode=\"save\", t=\"gray\"):\n",
    "  \n",
    "  '''\n",
    "  convert the input pixels from the single string row to  48*48 array with real pixel values\n",
    "  when mode = \"save\" it keeps the images in flat array shape, otherwise it converts it to 48*48\n",
    "  when t (for type) = \"gray, it keeps the pixels single channel, otherwise it converts it to 3 channels\n",
    "  '''\n",
    "\n",
    "  if type(pixels) == str:\n",
    "      pixels = np.array([int(i) for i in pixels.split()])\n",
    "  if mode == \"show\":\n",
    "    if t == \"gray\":\n",
    "      return pixels.reshape(48,48)\n",
    "    else:\n",
    "      return gray_to_rgb(pixels.reshape(48,48))\n",
    "  else:\n",
    "      return pixels\n",
    "\n",
    "data[\"pixels\"] = data[\"pixels\"].apply(lambda x : convert_to_image(x, mode=\"show\", t=\"gray\"))\n",
    "from sklearn.model_selection import train_test_split\n",
    "#split the data to train, test, and validation\n",
    "X_train, X_test, y_train, y_test = train_test_split(data[\"pixels\"],  data[\"emotion\"], test_size=0.2, random_state=1)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=1)\n",
    "\n",
    "X_train = np.array(list(X_train[:]), dtype=np.float)\n",
    "X_val = np.array(list(X_val[:]), dtype=np.float)\n",
    "X_test = np.array(list(X_test[:]), dtype=np.float)\n",
    "\n",
    "y_train = np.array(list(y_train[:]), dtype=np.float)\n",
    "y_val = np.array(list(y_val[:]), dtype=np.float)\n",
    "y_test = np.array(list(y_test[:]), dtype=np.float)\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], 48, 48, 1) \n",
    "X_val = X_val.reshape(X_val.shape[0], 48, 48, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 48, 48, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "afa2e2922ad58ba02230f21ea04dd2111ba6d7f3",
    "colab": {},
    "colab_type": "code",
    "id": "i-cuxb3oTMAZ"
   },
   "outputs": [],
   "source": [
    "num_train = X_train.shape[0]\n",
    "num_val = X_val.shape[0]\n",
    "num_test = X_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "8f3e1f9dd92afb91a6a5e11379a52b63009e5cc9",
    "colab": {},
    "colab_type": "code",
    "id": "jOiKTPoXTMAb"
   },
   "outputs": [],
   "source": [
    "y_train = np_utils.to_categorical(y_train, num_classes) \n",
    "# y_val = val_set.emotion \n",
    "y_val = np_utils.to_categorical(y_val, num_classes) \n",
    "# y_test = test_set.emotion \n",
    "y_test = np_utils.to_categorical(y_test, num_classes) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "cd67c48062a9306d8305bc28bc541f6de8e28f0a",
    "colab": {},
    "colab_type": "code",
    "id": "8lPBROafTMAe"
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator( \n",
    "    rescale=1./255,\n",
    "    rotation_range = 10,\n",
    "    horizontal_flip = True,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    fill_mode = 'nearest')\n",
    "\n",
    "testgen = ImageDataGenerator( \n",
    "    rescale=1./255\n",
    "    )\n",
    "datagen.fit(X_train)\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bb80295851d45b120743d33f592f4163b43b6ad7",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 591
    },
    "colab_type": "code",
    "id": "iomg5DSVTMAh",
    "outputId": "8ace2d80-14bb-455b-8ef8-8905269c3d28"
   },
   "outputs": [],
   "source": [
    "for X_batch, y_batch in datagen.flow(X_train, y_train, batch_size=9):\n",
    "    for i in range(0, 9): \n",
    "        pyplot.axis('off') \n",
    "        pyplot.subplot(330 + 1 + i) \n",
    "        # print(np.where(y_batch[i] == 1)[0][0])\n",
    "        pyplot.title(emotion_labels[np.where(y_batch[i] == 1)[0][0]])\n",
    "        pyplot.imshow(X_batch[i].reshape(48, 48), cmap=pyplot.get_cmap('gray'))\n",
    "    pyplot.axis('off') \n",
    "    pyplot.show() \n",
    "    break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "da9fc7ec9dbaab6954faa22a0a1dfdfd95bc27a1",
    "colab": {},
    "colab_type": "code",
    "id": "FtpKYQbNTMAm"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "train_flow = datagen.flow(X_train, y_train, batch_size=batch_size) \n",
    "val_flow = testgen.flow(X_val, y_val, batch_size=batch_size) \n",
    "test_flow = testgen.flow(X_test, y_test, batch_size=batch_size) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "qe32bKksTMAo",
    "outputId": "7dfb80d2-36ab-41c2-8915-91f8d0d689d7"
   },
   "outputs": [],
   "source": [
    " def conv_bn_relu(x, filters, kernel_size, strides):\n",
    "    x = tf.keras.layers.Conv2D(filters=filters, kernel_size=kernel_size, strides=strides, padding='same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "    return x\n",
    "\n",
    "def inverted_residual_block(x, filters, strides, expansion_factor):\n",
    "    in_channels = x.shape[-1]\n",
    "    # pointwise convolution 1x1\n",
    "    x = conv_bn_relu(x, filters=expansion_factor*in_channels, kernel_size=1, strides=1)\n",
    "    # depthwise convolution 3x3\n",
    "    x = tf.keras.layers.DepthwiseConv2D(kernel_size=3, strides=strides, padding='same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "    # pointwise convolution 1x1\n",
    "    x = tf.keras.layers.Conv2D(filters=filters, kernel_size=1, strides=1, padding='same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    # skip connection\n",
    "    if strides == 1 and in_channels == filters:\n",
    "        x = tf.keras.layers.Add()([x, x])\n",
    "    return x\n",
    "\n",
    "def mobilenet_v2(input_shape, num_classes):\n",
    "    inputs = tf.keras.layers.Input(shape=input_shape)\n",
    "    x = conv_bn_relu(inputs, filters=32, kernel_size=3, strides=2)\n",
    "    x = inverted_residual_block(x, filters=16, strides=1, expansion_factor=1)\n",
    "    x = inverted_residual_block(x, filters=24, strides=2, expansion_factor=6)\n",
    "    x = inverted_residual_block(x, filters=24, strides=1, expansion_factor=6)\n",
    "    x = inverted_residual_block(x, filters=32, strides=2, expansion_factor=6)\n",
    "    x = inverted_residual_block(x, filters=32, strides=1, expansion_factor=6)\n",
    "    x = inverted_residual_block(x, filters=32, strides=1, expansion_factor=6)\n",
    "    x = inverted_residual_block(x, filters=64, strides=2, expansion_factor=6)\n",
    "    x = inverted_residual_block(x, filters=64, strides=1, expansion_factor=6)\n",
    "    x = inverted_residual_block(x, filters=64, strides=1, expansion_factor=6)\n",
    "    x = inverted_residual_block(x, filters=64, strides=1, expansion_factor=6)\n",
    "    x = inverted_residual_block(x, filters=96, strides=1, expansion_factor=6)\n",
    "    x = inverted_residual_block(x, filters=96, strides=1, expansion_factor=6)\n",
    "    x = inverted_residual_block(x, filters=96, strides=1, expansion_factor=6)\n",
    "    x = inverted_residual_block(x, filters=160, strides=2, expansion_factor=6)\n",
    "    x = inverted_residual_block(x, filters=160, strides=1, expansion_factor=6)\n",
    "    x = inverted_residual_block(x, filters=160, strides=1, expansion_factor=6)\n",
    "    x = inverted_residual_block(x, filters=320, strides=1, expansion_factor=6)\n",
    "    x = conv_bn_relu(x, filters=1280, kernel_size=1, strides=1)\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    outputs = tf.keras.layers.Dense(num_classes, activation='softmax')(x)\n",
    "    model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "input_shape=(48,48,1)\n",
    "conv5_model = mobilenet_v2(input_shape, 7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "Sw5pWvDxTMAq",
    "outputId": "5469e764-0d2e-47f7-b607-c3ddfe0b9db1"
   },
   "outputs": [],
   "source": [
    "opt = Adam(lr=0.0001, decay=1e-6)\n",
    "conv5_model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "2f8e528c62477436ec78c1466ce639362600e89c",
    "colab": {},
    "colab_type": "code",
    "id": "4OJam_cTTMAt"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "filepath=\"weights_min_loss.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "78da0c9ed84cd3443e15c268165295098c1e37dd",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "b8MVtGkyTMAw",
    "outputId": "a22a890d-e1cd-4b7a-bcba-9eec027a805a"
   },
   "outputs": [],
   "source": [
    "num_epochs = 100  \n",
    "history = conv5_model.fit_generator(train_flow, \n",
    "                    steps_per_epoch=len(X_train) / batch_size, \n",
    "                    epochs=num_epochs,  \n",
    "                    verbose=2,  \n",
    "                    callbacks=callbacks_list,\n",
    "                    validation_data=val_flow,  \n",
    "                    validation_steps=len(X_val) / batch_size) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "witqzI3YXZdN"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "def visualize_acc(history):\n",
    "\n",
    "  train_loss=history.history['loss']\n",
    "  val_loss=history.history['val_loss']\n",
    "  train_acc=history.history['accuracy']\n",
    "  val_acc=history.history['val_accuracy']\n",
    "\n",
    "  epochs = range(len(train_acc))\n",
    "\n",
    "  plt.plot(epochs,train_loss,'r', label='train_loss')\n",
    "  plt.plot(epochs,val_loss,'b', label='val_loss')\n",
    "  plt.title('train_loss vs val_loss')\n",
    "  plt.xlabel('epoch')\n",
    "  plt.ylabel('loss')\n",
    "  plt.legend()\n",
    "  plt.figure()\n",
    "\n",
    "  plt.plot(epochs,train_acc,'r', label='train_acc')\n",
    "  plt.plot(epochs,val_acc,'b', label='val_acc')\n",
    "  plt.title('train_acc vs val_acc')\n",
    "  plt.xlabel('epoch')\n",
    "  plt.ylabel('accuracy')\n",
    "  plt.legend()\n",
    "  plt.figure()\n",
    "\n",
    "visualize_acc(history)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "fer-2013-notebook.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
